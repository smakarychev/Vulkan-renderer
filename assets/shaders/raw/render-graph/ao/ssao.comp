//https://wickedengine.net/2019/09/22/improved-normal-reconstruction-from-depth/

#version 460

#include "common.glsl"

#extension GL_EXT_samplerless_texture_functions: enable

const uint GROUP_SIZE = 16;
const uint TILE_SIZE = GROUP_SIZE + 2;

layout(local_size_x = GROUP_SIZE, local_size_y = GROUP_SIZE) in;

layout(constant_id = 0) const uint MAX_SAMPLES = 128;

shared vec2 s_positions[TILE_SIZE * TILE_SIZE];
shared float s_depths[TILE_SIZE * TILE_SIZE];

struct Settings {
    float power;
    float radius;
    uint samples;
};

struct Camera {
    mat4 projection;
    mat4 projection_inverse;
    float near;
    float far;
};

@immutable_sampler
layout(set = 0, binding = 0) uniform sampler u_depth_sampler;
@immutable_sampler_nearest
layout(set = 0, binding = 1) uniform sampler u_noise_sampler;

layout(set = 1, binding = 0) uniform texture2D u_noise_texture;
layout(set = 1, binding = 1) uniform texture2D u_depth_texture;
layout(set = 1, binding = 2, r8) uniform writeonly image2D u_ssao;

layout(set = 1, binding = 3) uniform settings {
    Settings settings;
} u_settings;

layout(set = 1, binding = 4) uniform samples {
    vec4 samples[MAX_SAMPLES];
} u_samples;

layout(set = 1, binding = 5) uniform camera {
    Camera camera;
} u_camera;

layout(push_constant) uniform push_constants {
    vec2 u_ssao_size_inv;
    vec2 u_ssao_size;
    vec2 u_noise_size_inv;
};

float linear_depth(float depth) {
    return linear_depth(depth, u_camera.camera.near, u_camera.camera.far);
}

void main() {
    const ivec2 top_left = ivec2(gl_WorkGroupID.xy * GROUP_SIZE) - 1;
    // we have a total of GROUP_SIZE * GROUP_SIZE threads, but each thread needs to access the surrounding texels,
    // which means that we have to calculate a total of (GROUP_SIZE + 1) * (GROUP_SIZE + 1) values,
    // the for loop below is a very simple way of splitting the work somewhat evenly across the available threads
    for (uint i = gl_LocalInvocationIndex; i < TILE_SIZE * TILE_SIZE; i += GROUP_SIZE * GROUP_SIZE) {
        const uvec2 pixel_coords = top_left + unflatten2d(i, TILE_SIZE);
        const vec2 uv = (vec2(pixel_coords) + 0.5f) * u_ssao_size_inv;
        const float depth = textureLod(sampler2D(u_depth_texture, u_depth_sampler), uv, 0).r;
        const vec3 position = reconstruct_position(uv, depth, u_camera.camera.projection_inverse);

        s_positions[i] = position.xy;
        s_depths[i] = position.z;
    }
    groupMemoryBarrier();
    
    // ids of neighbouring pixels + pixel itself
    const uint ids[5] = {
        flatten2d(1u + gl_LocalInvocationID.xy + ivec2( 0, 0), TILE_SIZE), // center
        flatten2d(1u + gl_LocalInvocationID.xy + ivec2( 1, 0), TILE_SIZE), // right
        flatten2d(1u + gl_LocalInvocationID.xy + ivec2(-1, 0), TILE_SIZE), // left
        flatten2d(1u + gl_LocalInvocationID.xy + ivec2( 0, 1), TILE_SIZE), // bottom
        flatten2d(1u + gl_LocalInvocationID.xy + ivec2( 0,-1), TILE_SIZE), // top
    };
    
    const float center_depth = s_depths[ids[0]];
    if (center_depth >= u_camera.camera.far)
        return;
    
    const uint best_horizontal = abs(s_depths[ids[1]] - center_depth) < abs(s_depths[ids[2]] - center_depth) ? 1 : 2;
    const uint best_vertical = abs(s_depths[ids[3]] - center_depth) < abs(s_depths[ids[4]] - center_depth) ? 3 : 4;
    
    vec3 p1, p2;
    if (best_horizontal + best_vertical == 5) {
        p1 = vec3(s_positions[ids[best_horizontal]], s_depths[ids[best_horizontal]]);
        p2 = vec3(s_positions[ids[best_vertical]], s_depths[ids[best_vertical]]);
    }
    else {
        p1 = vec3(s_positions[ids[best_vertical]], s_depths[ids[best_vertical]]);
        p2 = vec3(s_positions[ids[best_horizontal]], s_depths[ids[best_horizontal]]);
    }
    
    const vec3 center_position = vec3(s_positions[ids[0]], center_depth);
    const vec3 normal = normalize(cross(p2 - center_position, p1 - center_position));
    const vec2 uv = (vec2(gl_GlobalInvocationID.xy) + 0.5f) * u_ssao_size_inv;
    vec2 noise_uv = u_ssao_size * u_noise_size_inv * uv;
    vec3 noise = textureLod(sampler2D(u_noise_texture, u_noise_sampler), noise_uv, 0).rgb;

    const vec3 tangent = normalize(noise - normal * dot(noise, normal));
    const vec3 bitangent = cross(normal, tangent);
    const mat3 TBN = mat3(tangent, bitangent, normal);

    float ao = 0.0f;
    for (uint i = 0; i < u_settings.settings.samples; i++) {
        const vec3 sample_local = u_samples.samples[i].xyz;
        const vec3 sample_point = TBN * sample_local * u_settings.settings.radius + center_position;
        
        vec4 proj = u_camera.camera.projection * vec4(sample_point, 1.0f);
        proj.xyz /= proj.w;
        proj.xy = proj.xy * vec2(0.5f, -0.5f) + vec2(0.5f, 0.5f);
    
        if (is_saturated(proj.xy)) {
            const float depth_real = proj.z;
            const float depth_sample = textureLod(sampler2D(u_depth_texture, u_depth_sampler), proj.xy, 0).r;
            float depth_fix = smoothstep(0.0f, 1.0f,
                u_settings.settings.radius / abs(proj.w - linear_depth(depth_sample)));
            ao += float(depth_sample >= depth_real) * depth_fix;
        }
    }
    ao /= max(1.0f, float(u_settings.settings.samples));
    ao = pow(clamp(1.0f - ao, 0.0f, 1.0f), u_settings.settings.power);

    imageStore(u_ssao, ivec2(gl_GlobalInvocationID.xy), vec4(ao));
}